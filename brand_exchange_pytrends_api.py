# -*- coding: utf-8 -*-
"""Brand Exchange Pytrends API.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HA72gygY0E1EJwIXJyQlBVJEGXeKq2kw
"""

# @title Service account authentication

import gspread
import os
import json
from oauth2client.service_account import ServiceAccountCredentials

# Define the scope
scope = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']

# Load credentials from a string (we will store this string in GitHub Secrets later)
# This avoids saving the sensitive JSON file directly in your code
json_creds = os.environ['GCP_CREDENTIALS']
creds_dict = json.loads(json_creds)

creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
client = gspread.authorize(creds)
# @title Reading and storing the sheet into a DataFrame
# !pip install gspread pandas pytrends --quiet

import pandas as pd
import gspread
# from google.colab import auth
# from google.auth import default

# --- CONFIGURATION ---
SHEET_NAME = "BrandStreet_Seed_Data"

# 1. AUTHENTICATE
# try:
#     auth.authenticate_user()
#     creds, _ = default()
#     gc = gspread.authorize(creds)
#     print("Authentication Successful.")
# except Exception as e:
#     print(f"Auth Error: {e}")

# 2. READ SHEET
try:
    sh = gc.open(SHEET_NAME)
    worksheet = sh.sheet1

    # Get all records
    data = worksheet.get_all_records()

    if not data:
        print("Sheet is empty!")
    else:
        # Store in DataFrame
        df = pd.DataFrame(data)
        print(f"Success! Loaded {len(df)} brands into DataFrame.")
        print(df[['Brand Name', 'Google Keyword']].head()) # Preview

except Exception as e:
    print(f"Error reading sheet: {e}")

# @title Define the fetch Engine
from pytrends.request import TrendReq
import time
import random
import pandas as pd

# --- CONFIGURATION ---
ANCHOR_KEYWORD = "Nifty 50"
pytrends = TrendReq(hl='en-IN', tz=330)

def get_growth_metrics(keywords):
    metrics_map = {}

    # Chunking
    chunk_size = 4
    chunks = [keywords[i:i + chunk_size] for i in range(0, len(keywords), chunk_size)]

    print(f"Starting Growth Engine for {len(keywords)} brands...")

    for i, batch in enumerate(chunks):
        query_list = list(set([ANCHOR_KEYWORD] + batch))

        try:
            print(f"Processing Batch {i+1}/{len(chunks)}: {batch}")

            # Fetch 12 Months (Returns Weekly Data)
            pytrends.build_payload(query_list, cat=0, timeframe='today 12-m', geo='IN', gprop='')
            data = pytrends.interest_over_time()

            if data.empty:
                print("   -> No data.")
                continue

            # 1. Normalize against Anchor (Avoid Divide by Zero)
            data[ANCHOR_KEYWORD] = data[ANCHOR_KEYWORD].replace(0, 1)

            for kw in batch:
                if kw in data.columns:
                    # Normalize entire history first
                    # (Brand / Anchor) * 50
                    norm_series = (data[kw] / data[ANCHOR_KEYWORD]) * 50

                    # --- CALCULATE METRICS ---
                    # We need at least 53 weeks of data for YoY
                    if len(norm_series) >= 52:
                        # A. VOLUME (Current Period): Last 2 weeks average
                        curr_vol = norm_series.iloc[-2:].mean()

                        # B. PREV VOLUME (Previous Period): Weeks -3 and -4
                        prev_vol = norm_series.iloc[-4:-2].mean()

                        # C. LAST YEAR VOLUME (YoY Period): Same time last year
                        yoy_vol = norm_series.iloc[:2].mean() # Approx first 2 weeks of the 12m window

                        # --- GROWTH FORMULAS ---
                        # PoP %
                        if prev_vol > 0:
                            pop = ((curr_vol - prev_vol) / prev_vol)
                        else:
                            pop = 0

                        # YoY %
                        if yoy_vol > 0:
                            yoy = ((curr_vol - yoy_vol) / yoy_vol)
                        else:
                            yoy = 0

                        metrics_map[kw] = {
                            "Volume": round(curr_vol, 2),
                            "PoP": round(pop, 2),
                            "YoY": round(yoy, 2)
                        }
                    else:
                        # Fallback if brand is new (<1 year old)
                        metrics_map[kw] = {
                            "Volume": round(norm_series.iloc[-2:].mean(), 2),
                            "PoP": 0,
                            "YoY": 0
                        }

        except Exception as e:
            print(f"   -> Error: {e}")
            time.sleep(60)

        time.sleep(random.randint(8, 15))

    return metrics_map

print("Growth Engine Ready.")

# @title Execute & Update Sheet
from datetime import datetime

# 1. READ KEYWORDS
sh = gc.open(SHEET_NAME)
worksheet = sh.sheet1
df = pd.DataFrame(worksheet.get_all_records())

if not df.empty:
    keywords_list = df['Google Keyword'].tolist()

    # 2. RUN ENGINE
    results = get_growth_metrics(keywords_list)

    print("\n--- Update Started ---")

    # 3. PREPARE UPDATE
    # Map headers to column numbers (1-based)
    headers = worksheet.row_values(1)
    try:
        col_vol = headers.index("Volume (14-Day Avg)") + 1
        col_pop = headers.index("Growth PoP %") + 1
        col_yoy = headers.index("Growth YoY %") + 1
        col_time = headers.index("Last Updated") + 1
    except ValueError:
        print("Error: Columns not found. Run Cell 1 (Migration) first.")
        col_vol = None

    if col_vol:
        cells_to_update = []
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")

        for index, row in df.iterrows():
            kw = row['Google Keyword']
            row_num = index + 2

            if kw in results:
                data = results[kw]

                # Volume
                cells_to_update.append({'range': gspread.utils.rowcol_to_a1(row_num, col_vol), 'values': [[data['Volume']]]})
                # PoP
                cells_to_update.append({'range': gspread.utils.rowcol_to_a1(row_num, col_pop), 'values': [[data['PoP']]]})
                # YoY
                cells_to_update.append({'range': gspread.utils.rowcol_to_a1(row_num, col_yoy), 'values': [[data['YoY']]]})
                # Time
                cells_to_update.append({'range': gspread.utils.rowcol_to_a1(row_num, col_time), 'values': [[timestamp]]})

        if cells_to_update:
            worksheet.batch_update(cells_to_update)
            print(f"SUCCESS! Updated {len(results)} brands with Growth Metrics.")
        else:
            print("No data found.")
